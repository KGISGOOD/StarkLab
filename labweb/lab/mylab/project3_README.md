# project_3：水利署國際新聞機器人

## 目錄
- [專案簡介](#專案簡介)
- [技術架構圖](#技術架構圖)
- [細項功能介紹](#細項功能介紹)

## 專案簡介
#### 本專案開發了一個自動化機器人，能夠在網路上搜尋並整理最近 7 天內發生於國際間的重大天災資訊，並將其推播給民眾。目標是透過即時資訊提高防災意識，幫助公眾及早應對可能的災害。

## 功能介紹
- **資料搜尋**：從可靠的國際新聞與氣象網站蒐集與國際相關的天災資訊。
- **災害分類**：識別並分類以下類型的天災：
  - 🌧 **水災類**：大雨、豪雨、暴雨、淹水、洪水、水災
  - 🌀 **氣旋類**：颱風、颶風、風災
  - 🌊 **地震與海嘯**：海嘯、地震
  - ☀ **乾旱與火災**：乾旱、旱災、野火
- **資料處理**：過濾、整理並提取關鍵資訊，以確保內容準確且具備時效性。
- **自動推播**：將處理後的天災資訊透過指定的通訊管道（如 LINE）推送給使用者。

## 🏗 技術架構圖：
## ![架構圖](/labweb/lab/架構圖.jpg)

## 細項功能介紹

[爬蟲](#爬蟲)  
[AI 處理](#ai-處理)  
[Post to API](#post-to-api)  

## 爬蟲

#### 主要分成兩個部分的爬蟲，分別是[google news](#google-news)和[各別新聞網](#各別新聞網)兩個爬蟲

## google news 

本函式 fetch_news(url) 用於從 **google news** 抓取新聞標題、來源和時間，並整理成結構化數據。

### 🚀 功能介紹
- 爬取 **Google News** 上的新聞資訊
- 解析新聞標題、來源與時間
- 過濾新聞來源，僅保留允許的來源
- 轉換相對路徑為完整新聞網址

### 📝 函式
```python
def fetch_news(url):
```
** 完整程式碼：[project3_views.py](/labweb/lab/mylab/project3_views.py)

## 各別新聞網

#### 主要分成兩個爬蟲，涵蓋[內文與圖片](#內文與圖片)

## 內文與圖片

- `def fetch_article_content(driver, sources_urls):` 用於從各新聞來源網站抓取文章內文

- `def extract_image_url(driver, sources_urls):` 用於從各新聞來源網站抓取圖片連結

### 🚀 功能介紹
- 爬取多個新聞來源（如 Newtalk 新聞、經濟日報、自由時報、BBC News 中文）的內文與圖片
- 使用來源特定的 CSS 選擇器提取段落內容與圖片元素
- 生成前 100 字摘要並處理 Google News 跳轉
- 特別處理 BBC News 中文圖片提取
- 包含異常處理，失敗時返回「錯誤」或空字串

** 完整程式碼：[project3_views.py](/labweb/lab/mylab/project3_views.py)

## AI 處理

使用 Prompt Engineering 搭配 AI API 來處理資料，透過精確設計的提示語（prompts）引導模型進行特定任務，如資料分類、文字分析或模式識別，從而實現高效、準確的自動化數據處理

以下為 AI 處理流程中的各個函式，點擊連結查看詳細說明：

- [確認是否災害](#確認是否災害)
- [判斷是否為相同事件](#判斷是否為相同事件)
- [事件分類](#事件分類)
- [概述生成](#概述生成)

---

## 確認是否災害

本函式 `is_disaster_news(title, content)` 用於判斷新聞是否主要報導自然災害事件。

### 🚀 功能介紹
- 判斷新聞是否聚焦於災害事件（如大雨、颱風、地震等）
- 使用 **X.AI** 分析新聞標題與內容，透過精確的 **Prompt Engineering** 排除非災害主題的報導（如救援活動、政策討論等）
- 精細化的判斷標準，僅將核心報導災害事件的新聞返回 `True`
- 加入重試機制處理 **API 失敗**，使用指數退避策略確保程式穩定運行
- 逐行讀取 CSV 檔案，並根據判斷結果過濾出災害新聞，最後將結果儲存至新的 CSV 檔案

### 📝 函式
```python
def is_disaster_news(title, content):
```
** 完整程式碼：[project3_views.py](/labweb/lab/mylab/project3_views.py)

## 判斷是否為相同事件

本函式 `extract_information(news_content)` 用於從新聞內文提取國家、地點和災害資訊。

### 🚀 功能介紹
- 使用 **AI** 提取新聞內文中的單一國家、多個地點以及單一災害類型
- 支援災害類型（如洪水、野火等）的標準化處理，確保正確識別與分類
- 加入重試機制應對 **API 錯誤**，提高程式穩定性
- 輸出結構化結果，確保資訊的完整性與一致性
- 最終結果會儲存為 `add_locations.csv` 檔案，並包含以下欄位：國家、地點、災害

### 📝 函式
```python
def extract_information(news_content):
```
** 完整程式碼：[project3_views.py](/labweb/lab/mylab/project3_views.py)

## 事件分類

本函式 `extract_information(news_title, news_content)` 用於判斷災害事件並生成事件名稱與摘要。

### 🚀 功能介紹
- 使用 **AI** 提取單一國家、多個地點及單一災害類型，並根據新聞標題和內文生成唯一事件名稱
- 支援災害類型（如洪水、野火等）的標準化處理，確保災害事件名稱的一致性
- 判斷新聞標題與內文是否描述相同災害事件，並合併為統一的事件名稱
- 生成災害事件摘要，精確反映核心信息（50-100字），並統整損失數據及災害影響範圍
- 加入重試機制應對 **API 錯誤**，提高程式穩定性
- 輸出結構化結果，確保資訊的完整性與一致性
- 最終結果會儲存為 `add_events.csv` 檔案，並包含以下欄位：事件名稱、摘要、損失統整


### 📝 函式
```python
def extract_information(news_title,news_content):
```
** 完整程式碼：[project3_views.py](/labweb/lab/mylab/project3_views.py)

## 概述生成

本函式 `def generate_overview(group):` 用於判斷災害事件並生成事件名稱與摘要。

### 🚀 功能介紹

- **災害資訊摘要生成**：根據事件摘要（summary）與內文自動生成災害總整理，包含國家、地點、災害類型、影響範圍與後續發展等要素。
- **時間處理精確**：支持從內文中識別明確的災害發生時間（如具體日期）或相對時間（如“今天”、“昨日”）並轉換為標準日期格式。
- **時間準確性檢查**：若內文提及災害時間，摘要會確保時間為災害發生的時間，而非其他無關時間（如新聞發布時間）。
- **結構化摘要**：生成的災害資訊摘要將包含地點、災害類型、影響範圍，並按照時間順序整理。
- **字數控制**：每個災害摘要控制在 100-150 字之間，提供簡潔但完整的資訊。
- **範例與檢核標準**：提供範例摘要，並依據檢核標準確保每個摘要符合時間準確性、內容完整性和結構清晰性。

### 📝 函式
```python
def generate_overview(group):
```
** 完整程式碼：[project3_views.py](/labweb/lab/mylab/project3_views.py)


## Post to API
搭配django裡面內建api功能將ai處理好的json檔post到api上

#### 以下是查看api網址
```網址
http://localhost:8000/api/news/sql/  
```



